{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q dask_cuda torch torchtext skorch\n",
    "!pip -q install dask[dataframe] --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization with Skorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:42413</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>33.68 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:42413' processes=1 threads=1, memory=33.68 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from distributed import Client\n",
    "\n",
    "# if you have GPU(s), use dask_cuda to automatically make use of them in your dask cluster\n",
    "if torch.cuda.is_available():\n",
    "    cluster = LocalCUDACluster()\n",
    "    client = Client(cluster)\n",
    "else:\n",
    "    client = Client(processes=False, threads_per_worker=4,\n",
    "                    n_workers=1, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes approx. 10 minutes to download data and embeddings (will be cached for re-use)\n",
    "\n",
    "# set up fields\n",
    "TEXT = data.Field(lower=True, include_lengths=True, batch_first=True, )\n",
    "LABEL = data.Field(sequential=False, unk_token=None)\n",
    "\n",
    "# make splits for data\n",
    "train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "# will be used to initialize model embeddings layer\n",
    "vocab = torchtext.vocab.GloVe(name='6B', dim=100)\n",
    "\n",
    "# build the vocabulary\n",
    "max_size = 25_000 # shorten for demonstrative purposes\n",
    "TEXT.build_vocab(train, vectors=vocab, max_size=max_size)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "# make iterator for splits\n",
    "train_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train, test), batch_sizes=(32, 64), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', 'a', 'and']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# itos := index-to-string\n",
    "# note the 2 extra tokens added for us: '<unk>', '<pad>'\n",
    "TEXT.vocab.itos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(TEXT.vocab.itos) == max_size + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'masterful', 'treatment', 'of', 'james', \"caine's\", '\"the', 'postman', 'always', 'rings', 'twice\"', 'as', 'luchino', \"visconti's\", 'first', 'film', 'shot', 'primarily', 'around', 'ferrara', 'in', 'a', 'soulless', 'war-torn', 'italy.', 'the', 'original', 'negative', 'was', 'thought', 'destroyed', 'but', 'visconti', 'saved', 'a', 'print', 'and', 'fortunately', 'we', 'can', 'see', 'this', 'early', 'neo-realist', 'work', 'today.', 'a', 'ruggedly', 'handsome', 'massimo', 'girotti', 'and', 'clara', 'calamai', '(who', 'had', 'recently', 'revealed', 'her', 'breasts', 'in', 'la', 'cena', 'delle', 'beffe\"', '(1941),', 'star', 'as', 'the', 'sensually-charged', 'and', 'ill-fated', 'lovers', 'who', 'plot', 'to', 'kill', 'her', 'husband.', 'unusual', 'ending', 'in', 'which,', 'although', 'crime', 'does', 'not', 'pay,', 'one', 'pays', 'in', 'a', 'way', 'not', 'directly', 'linked', 'to', 'the', 'crime.', 'excellent', 'direction,', 'script,', 'acting,', 'and', 'cinematography.', 'reportedly', 'not', 'as', 'good', 'as', 'the', 'french', '\"le', 'dernier', \"tournant'\", '(1939)', 'but', 'probably', 'better', 'than', 'the', 'us', 'version', '(1946)', 'featuring', 'lana', 'turner', 'and', 'john', 'garfield', 'in', 'the', 'lead', 'roles.', 'highly', 'recommended.']\n",
      "\n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "# peek at the data\n",
    "print(train.examples[0].text)\n",
    "print()\n",
    "print(train.examples[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sadly train_iter isn't actually an iter..\n",
    "# peek at a batch of data\n",
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  542,  5101,    41,  ...,     1,     1,     1],\n",
      "        [   10,     7,    31,  ...,     1,     1,     1],\n",
      "        [    0,    49, 15842,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [   25,    86,   311,  ...,     1,     1,     1],\n",
      "        [    9,   157,   168,  ...,     1,     1,     1],\n",
      "        [   10,    49,   235,  ...,     1,     1,     1]])\n",
      "tensor([132, 121,  72, 343, 112,  90, 226, 982, 118, 341, 145,  64, 149,  87,\n",
      "        244, 270, 122,  94, 141,  76, 154, 151, 429,  97, 104,  76, 120, 125,\n",
      "        120, 118, 134, 154])\n"
     ]
    }
   ],
   "source": [
    "# numericalized tokens\n",
    "print(batch.text[0])\n",
    "# sequence lengths\n",
    "print(batch.text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'neg': 0, 'pos': 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stoi := string-to-index\n",
    "# check on the meaning of these zeroes and ones\n",
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# was having trouble with when model was defined in the notebook\n",
    "# Can't get attribute ‘CNN' on <module ‘__main__'\n",
    "from model import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4698, 0.5302],\n",
       "        [0.3791, 0.6209],\n",
       "        [0.2715, 0.7285],\n",
       "        [0.3220, 0.6780],\n",
       "        [0.3979, 0.6021],\n",
       "        [0.4197, 0.5803],\n",
       "        [0.3409, 0.6591],\n",
       "        [0.2695, 0.7305],\n",
       "        [0.4400, 0.5600],\n",
       "        [0.4209, 0.5791],\n",
       "        [0.4640, 0.5360],\n",
       "        [0.4475, 0.5525],\n",
       "        [0.4261, 0.5739],\n",
       "        [0.3032, 0.6968],\n",
       "        [0.3452, 0.6548],\n",
       "        [0.3803, 0.6197],\n",
       "        [0.3741, 0.6259],\n",
       "        [0.3796, 0.6204],\n",
       "        [0.5005, 0.4995],\n",
       "        [0.3706, 0.6294],\n",
       "        [0.3142, 0.6858],\n",
       "        [0.3772, 0.6228],\n",
       "        [0.3281, 0.6719],\n",
       "        [0.3190, 0.6810],\n",
       "        [0.3340, 0.6660],\n",
       "        [0.3948, 0.6052],\n",
       "        [0.2351, 0.7649],\n",
       "        [0.4538, 0.5462],\n",
       "        [0.2321, 0.7679],\n",
       "        [0.4226, 0.5774],\n",
       "        [0.2449, 0.7551],\n",
       "        [0.3471, 0.6529]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smoketest\n",
    "model = CNN(pretrained_embeddings=TEXT.vocab.vectors).to(device)\n",
    "gpu_batch = batch.text[0].to(device)\n",
    "model(gpu_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gpu_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick attempt at model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skorch\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a really unfortunate hack to make torchtext batching semantics work with skorch and dask\n",
    "# the downside here is that we're no longer padding to the longest sequence in the batch, rather\n",
    "# we're padding to the longest sequence in the *dataset*, which results in signifcantly more\n",
    "# computation and thus significantly more time to train a model\n",
    "# of course, you could set a max sequence length but that's not an ideal solution\n",
    "# another solution would be to create a different dataset object, but then you can't use torchtext,\n",
    "# which really is quite handy\n",
    "\n",
    "# train=True shuffles the data\n",
    "train_iter_skorch = torchtext.data.Iterator(train, batch_size=len(train), train=True, sort=False, device='cpu')\n",
    "test_iter_skorch = torchtext.data.Iterator(test, batch_size=len(test), train=False, sort=False, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes some time to numericalize the whole dataset\n",
    "\n",
    "# also notice that skorch and dask expect numpy arrays, which isn't ideal since it ties you to the cpu.\n",
    "# meanwhile, projects like https://rapids.ai/ are moving toward all GPU computation, avoiding the cpu altogether.\n",
    "for batch in train_iter_skorch:\n",
    "    X_train = batch.text[0].numpy()\n",
    "    y_train = batch.label.numpy()\n",
    "\n",
    "for batch in test_iter_skorch:\n",
    "    X_test = batch.text[0].numpy()\n",
    "    y_test = batch.label.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2470)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice how awfully large the second dimension is\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: not ideal to be using softmax + log + NLLLoss\n",
    "# see discussion: https://github.com/skorch-dev/skorch/issues/637\n",
    "skorch_model = NeuralNetClassifier(\n",
    "                CNN,\n",
    "                device=device,\n",
    "                max_epochs=2,\n",
    "                lr=0.001,\n",
    "                optimizer=optim.Adam,\n",
    "                criterion=nn.NLLLoss,\n",
    "                train_split=skorch.dataset.CVSplit(.2), # NB: this witholds 20% of the training data for validation\n",
    "                module__n_filters=100,\n",
    "                module__filter_sizes=(2,3,4),\n",
    "                module__dropout=0.2,\n",
    "                module__pretrained_embeddings=TEXT.vocab.vectors,\n",
    "                batch_size=32,\n",
    "                verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.4689\u001b[0m       \u001b[32m0.8370\u001b[0m        \u001b[35m0.3656\u001b[0m  60.5744\n",
      "      2        \u001b[36m0.3466\u001b[0m       \u001b[32m0.8524\u001b[0m        \u001b[35m0.3413\u001b[0m  58.6526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=CNN(\n",
       "    (embedding): Embedding(25002, 100)\n",
       "    (conv_0): Conv1d(1, 100, kernel_size=(2, 100), stride=(1,))\n",
       "    (conv_1): Conv1d(1, 100, kernel_size=(3, 100), stride=(1,))\n",
       "    (conv_2): Conv1d(1, 100, kernel_size=(4, 100), stride=(1,))\n",
       "    (fc): Linear(in_features=300, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skorch_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85512"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick check on the test set accuracy\n",
    "skorch_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([12500, 12500]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random guessing would 50% accuracy so the model is indeed training\n",
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: this has no effect on GPU memory usage. If I keyboard interrupt, the workers get\n",
    "# restarted and memory usage goes down. Deleting these \"handler\" objects doesn't delete\n",
    "# GPU memory references on the workers. \n",
    "del skorch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search with Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ml.dask.org/hyper-parameter-search.html#hyperband-parameters-rule-of-thumb\n",
    "EPOCHS = 5\n",
    "NUM_TRAINING_EXAMPLES = len(train)*.8\n",
    "n_examples = EPOCHS * NUM_TRAINING_EXAMPLES\n",
    "n_params = 8\n",
    "\n",
    "# it's not immediately obvious to beginners how all these parameters interact with each other\n",
    "max_iter = n_params\n",
    "chunk_size = n_examples // n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose we want to set max_iter to be the commensurate with the number of examples required\n",
    "# for the model converge (as cited in the documentation)\n",
    "\n",
    "# it's a bit unclear how n_params relates to BOTH the number of data points required\n",
    "# for the model to converge AND how many hyperparameters to try out (i.e. n_iter in RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size: 12500.0\n",
      "Total chunks: 2\n",
      "Last chunk size: 12500.0\n"
     ]
    }
   ],
   "source": [
    "# choose chunk size so that the remainder is not a tiny number\n",
    "print(f'Chunk size: {chunk_size}')\n",
    "print(f'Total chunks: {math.ceil(len(X_train) / chunk_size)}')\n",
    "last_chunk_size = len(X_train) % chunk_size\n",
    "if last_chunk_size == 0: # i.e. chunk_size evenly divides X_train\n",
    "    last_chunk_size = chunk_size\n",
    "print(f'Last chunk size: {last_chunk_size}')\n",
    "\n",
    "assert (len(X_train) % chunk_size > 10 or len(X_train) % chunk_size == 0), 'Choose another chunk size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "X = da.from_array(X_train, chunks=(chunk_size, X_train.shape[-1]))\n",
    "y = da.from_array(y_train, chunks=(chunk_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 494.00 MB </td> <td> 247.00 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (25000, 2470) </td> <td> (12500, 2470) </td></tr>\n",
       "    <tr><th> Count </th><td> 3 Tasks </td><td> 2 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"88\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"38\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"38\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"38\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"38\" y1=\"0\" x2=\"38\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 38.529848,0.000000 38.529848,120.000000 0.000000,120.000000\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"19.264924\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >2470</text>\n",
       "  <text x=\"58.529848\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,58.529848,60.000000)\">25000</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(25000, 2470), dtype=int64, chunksize=(12500, 2470), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitialize and set train_split=None to let hyperband handle validation set splitting\n",
    "skorch_model = NeuralNetClassifier(\n",
    "                CNN,\n",
    "                device=device,\n",
    "                lr=0.001,\n",
    "                optimizer=optim.Adam,\n",
    "                criterion=nn.NLLLoss,\n",
    "                train_split=None, # let hyperband handle it\n",
    "                module__n_filters=100,\n",
    "                module__filter_sizes=(2, 3, 4),\n",
    "                module__dropout=0.2,\n",
    "                module__pretrained_embeddings=TEXT.vocab.vectors,\n",
    "                batch_size=32,\n",
    "                verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter grid\n",
    "params = {'module__filter_sizes': [(1, 2, 3), (2, 3, 4), (3, 4, 5)], \n",
    "          'module__n_filters': [25, 50, 100],\n",
    "          'module__dropout': loguniform(1e-1, 3e-1),\n",
    "          'batch_size': [32, 64],\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import HyperbandSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HyperbandSearchCV(\n",
    "    skorch_model,\n",
    "    params,\n",
    "    max_iter=max_iter,\n",
    "    verbose=True,\n",
    "    test_size=0.2 # validation size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.metadata[\"partial_fit_calls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.metadata['n_models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to clear up any confusion, every time partial_fit is called, we're passing in chunk_size number of\n",
    "# data points. Then skorch handles the batch size either by being set explicitly or as part of the param grid.\n",
    "\n",
    "# to compare this grid search to number of epochs, we have 26 partial_fit calls * 10k data points = 260k examples\n",
    "# with a training set size of 25k * .8 = 20k data points, this is 13 epochs!\n",
    "# considering that it takes approximately 5 epochs to train a model, you would get through less than 3 sets of \n",
    "# hyperparameters if manually searching. Instead we'll search through ~5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV, bracket=1] creating 3 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/distributed/worker.py:3379: UserWarning: Large object of size 10.00 MB detected in task graph: \n",
      "  [<class 'skorch.classifier.NeuralNetClassifier'>[u ... .0721]]),\n",
      "), 0]\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  % (format_bytes(len(b)), s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV, bracket=0] creating 2 models\n",
      "[CV, bracket=0] For training there are between 10000 and 10000 examples in each chunk\n",
      "[CV, bracket=1] For training there are between 10000 and 10000 examples in each chunk\n",
      "[CV, bracket=0] validation score of 0.8386 received after 1 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.8306 received after 1 partial_fit calls\n",
      "[CV, bracket=0] validation score of 0.8446 received after 8 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.8430 received after 2 partial_fit calls\n",
      "[CV, bracket=1] validation score of 0.8456 received after 6 partial_fit calls\n",
      "Time to complete grid search: 3813.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# it's been erroring out with a less than helpful error message. This started happening right around \n",
    "# when I started passing module__pretrained_embeddings=vocab.vectors. Unclear if this is the culprit.\n",
    "\n",
    "# NB: this took ~3800 seconds on a single Nvidia GTX 980 Ti\n",
    "# notice how the number of training datapoints relates to the chunk size and our test_size\n",
    "# e.g. Validation set size: 2500 = 12500*.2, Train set size: 10000 = 12500 - 2500\n",
    "start = time.time()\n",
    "search.fit(X, y)\n",
    "end = time.time()\n",
    "duration = round(end - start, 2)\n",
    "print(f'Time to complete grid search: {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.333333333333336"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3800 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HyperbandSearchCV` follows the Scikit-learn API and mirrors Scikit-learn's `RandomizedSearchCV`. This means that it \"just works\". All the Scikit-learn attributes and methods are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8456"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=CNN(\n",
       "    (embedding): Embedding(25002, 100)\n",
       "    (conv_0): Conv1d(1, 50, kernel_size=(3, 100), stride=(1,))\n",
       "    (conv_1): Conv1d(1, 50, kernel_size=(4, 100), stride=(1,))\n",
       "    (conv_2): Conv1d(1, 50, kernel_size=(5, 100), stride=(1,))\n",
       "    (fc): Linear(in_features=150, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.22181138802671369, inplace=False)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'param_module__n_filters': array([50, 50, 50, 25, 50]),\n",
       " 'test_score': array([0.8456, 0.7982, 0.733 , 0.843 , 0.8446]),\n",
       " 'std_score_time': array([0.06216696, 0.19731486, 0.56393194, 1.33936262, 0.06445384]),\n",
       " 'rank_test_score': array([1, 2, 3, 2, 1]),\n",
       " 'mean_score_time': array([3.82462454, 4.0282222 , 5.47523713, 4.41082978, 5.29884744]),\n",
       " 'params': array([{'batch_size': 64, 'module__dropout': 0.22181138802671369, 'module__filter_sizes': (3, 4, 5), 'module__n_filters': 50},\n",
       "        {'batch_size': 64, 'module__dropout': 0.19188105885296006, 'module__filter_sizes': (3, 4, 5), 'module__n_filters': 50},\n",
       "        {'batch_size': 32, 'module__dropout': 0.11893575283135104, 'module__filter_sizes': (3, 4, 5), 'module__n_filters': 50},\n",
       "        {'batch_size': 32, 'module__dropout': 0.10900910968190201, 'module__filter_sizes': (2, 3, 4), 'module__n_filters': 25},\n",
       "        {'batch_size': 32, 'module__dropout': 0.10009422737462631, 'module__filter_sizes': (3, 4, 5), 'module__n_filters': 50}],\n",
       "       dtype=object),\n",
       " 'partial_fit_calls': array([6, 2, 2, 8, 8]),\n",
       " 'param_module__dropout': array([0.22181139, 0.19188106, 0.11893575, 0.10900911, 0.10009423]),\n",
       " 'std_partial_fit_time': array([ 3.6288025 ,  1.52035153, 11.09951091, 15.07569551,  5.98224938]),\n",
       " 'mean_partial_fit_time': array([ 93.61417103,  96.36260712, 136.89576507, 143.69626164,\n",
       "        130.64727747]),\n",
       " 'model_id': array(['bracket=1-0', 'bracket=1-1', 'bracket=1-2', 'bracket=0-0',\n",
       "        'bracket=0-1'], dtype='<U11'),\n",
       " 'bracket': array([1, 1, 1, 0, 0]),\n",
       " 'param_batch_size': array([64, 64, 32, 32, 32]),\n",
       " 'param_module__filter_sizes': array([[3, 4, 5],\n",
       "        [3, 4, 5],\n",
       "        [3, 4, 5],\n",
       "        [2, 3, 4],\n",
       "        [3, 4, 5]])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-245daea12296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    409\u001b[0m             )\n\u001b[1;32m    410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         ]\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             val = sanitize_array(\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             )\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(search.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue with numpy converting array of tuples into a 2d array\n",
    "search.cv_results_['param_module__filter_sizes'] = search.cv_results_['param_module__filter_sizes'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_module__n_filters</th>\n",
       "      <th>test_score</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>partial_fit_calls</th>\n",
       "      <th>param_module__dropout</th>\n",
       "      <th>std_partial_fit_time</th>\n",
       "      <th>mean_partial_fit_time</th>\n",
       "      <th>model_id</th>\n",
       "      <th>bracket</th>\n",
       "      <th>param_batch_size</th>\n",
       "      <th>param_module__filter_sizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>0.062167</td>\n",
       "      <td>1</td>\n",
       "      <td>3.824625</td>\n",
       "      <td>{'batch_size': 64, 'module__dropout': 0.221811...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.221811</td>\n",
       "      <td>3.628802</td>\n",
       "      <td>93.614171</td>\n",
       "      <td>bracket=1-0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.197315</td>\n",
       "      <td>2</td>\n",
       "      <td>4.028222</td>\n",
       "      <td>{'batch_size': 64, 'module__dropout': 0.191881...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>1.520352</td>\n",
       "      <td>96.362607</td>\n",
       "      <td>bracket=1-1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.563932</td>\n",
       "      <td>3</td>\n",
       "      <td>5.475237</td>\n",
       "      <td>{'batch_size': 32, 'module__dropout': 0.118935...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.118936</td>\n",
       "      <td>11.099511</td>\n",
       "      <td>136.895765</td>\n",
       "      <td>bracket=1-2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>0.8430</td>\n",
       "      <td>1.339363</td>\n",
       "      <td>2</td>\n",
       "      <td>4.410830</td>\n",
       "      <td>{'batch_size': 32, 'module__dropout': 0.109009...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.109009</td>\n",
       "      <td>15.075696</td>\n",
       "      <td>143.696262</td>\n",
       "      <td>bracket=0-0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.8446</td>\n",
       "      <td>0.064454</td>\n",
       "      <td>1</td>\n",
       "      <td>5.298847</td>\n",
       "      <td>{'batch_size': 32, 'module__dropout': 0.100094...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.100094</td>\n",
       "      <td>5.982249</td>\n",
       "      <td>130.647277</td>\n",
       "      <td>bracket=0-1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>[3, 4, 5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_module__n_filters  test_score  std_score_time  rank_test_score  \\\n",
       "0                       50      0.8456        0.062167                1   \n",
       "1                       50      0.7982        0.197315                2   \n",
       "2                       50      0.7330        0.563932                3   \n",
       "3                       25      0.8430        1.339363                2   \n",
       "4                       50      0.8446        0.064454                1   \n",
       "\n",
       "   mean_score_time                                             params  \\\n",
       "0         3.824625  {'batch_size': 64, 'module__dropout': 0.221811...   \n",
       "1         4.028222  {'batch_size': 64, 'module__dropout': 0.191881...   \n",
       "2         5.475237  {'batch_size': 32, 'module__dropout': 0.118935...   \n",
       "3         4.410830  {'batch_size': 32, 'module__dropout': 0.109009...   \n",
       "4         5.298847  {'batch_size': 32, 'module__dropout': 0.100094...   \n",
       "\n",
       "   partial_fit_calls  param_module__dropout  std_partial_fit_time  \\\n",
       "0                  6               0.221811              3.628802   \n",
       "1                  2               0.191881              1.520352   \n",
       "2                  2               0.118936             11.099511   \n",
       "3                  8               0.109009             15.075696   \n",
       "4                  8               0.100094              5.982249   \n",
       "\n",
       "   mean_partial_fit_time     model_id  bracket  param_batch_size  \\\n",
       "0              93.614171  bracket=1-0        1                64   \n",
       "1              96.362607  bracket=1-1        1                64   \n",
       "2             136.895765  bracket=1-2        1                32   \n",
       "3             143.696262  bracket=0-0        0                32   \n",
       "4             130.647277  bracket=0-1        0                32   \n",
       "\n",
       "  param_module__filter_sizes  \n",
       "0                  [3, 4, 5]  \n",
       "1                  [3, 4, 5]  \n",
       "2                  [3, 4, 5]  \n",
       "3                  [2, 3, 4]  \n",
       "4                  [3, 4, 5]  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(search.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83816"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 200.00 kB </td> <td> 200.00 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (25000,) </td> <td> (25000,) </td></tr>\n",
       "    <tr><th> Count </th><td> 2 Tasks </td><td> 1 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.000000,0.000000 120.000000,0.000000 120.000000,25.412617 0.000000,25.412617\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >25000</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<_predict, shape=(25000,), dtype=int64, chunksize=(25000,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.predict(X_test).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also has some other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>params</th>\n",
       "      <th>partial_fit_calls</th>\n",
       "      <th>partial_fit_time</th>\n",
       "      <th>score</th>\n",
       "      <th>score_time</th>\n",
       "      <th>elapsed_wall_time</th>\n",
       "      <th>bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bracket=0-0</td>\n",
       "      <td>{'batch_size': 32, 'module__dropout': 0.109009...</td>\n",
       "      <td>1</td>\n",
       "      <td>128.620566</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>3.071467</td>\n",
       "      <td>358.527012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bracket=0-1</td>\n",
       "      <td>{'batch_size': 32, 'module__dropout': 0.100094...</td>\n",
       "      <td>1</td>\n",
       "      <td>124.665028</td>\n",
       "      <td>0.8386</td>\n",
       "      <td>5.234394</td>\n",
       "      <td>358.527018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bracket=1-0</td>\n",
       "      <td>{'batch_size': 64, 'module__dropout': 0.221811...</td>\n",
       "      <td>1</td>\n",
       "      <td>95.602639</td>\n",
       "      <td>0.7558</td>\n",
       "      <td>3.739039</td>\n",
       "      <td>460.180206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bracket=1-1</td>\n",
       "      <td>{'batch_size': 64, 'module__dropout': 0.191881...</td>\n",
       "      <td>1</td>\n",
       "      <td>94.842256</td>\n",
       "      <td>0.7496</td>\n",
       "      <td>4.225537</td>\n",
       "      <td>460.180212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bracket=1-2</td>\n",
       "      <td>{'batch_size': 32, 'module__dropout': 0.118935...</td>\n",
       "      <td>1</td>\n",
       "      <td>125.796254</td>\n",
       "      <td>0.8306</td>\n",
       "      <td>6.039169</td>\n",
       "      <td>460.180215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_id                                             params  \\\n",
       "0  bracket=0-0  {'batch_size': 32, 'module__dropout': 0.109009...   \n",
       "1  bracket=0-1  {'batch_size': 32, 'module__dropout': 0.100094...   \n",
       "2  bracket=1-0  {'batch_size': 64, 'module__dropout': 0.221811...   \n",
       "3  bracket=1-1  {'batch_size': 64, 'module__dropout': 0.191881...   \n",
       "4  bracket=1-2  {'batch_size': 32, 'module__dropout': 0.118935...   \n",
       "\n",
       "   partial_fit_calls  partial_fit_time   score  score_time  elapsed_wall_time  \\\n",
       "0                  1        128.620566  0.8272    3.071467         358.527012   \n",
       "1                  1        124.665028  0.8386    5.234394         358.527018   \n",
       "2                  1         95.602639  0.7558    3.739039         460.180206   \n",
       "3                  1         94.842256  0.7496    4.225537         460.180212   \n",
       "4                  1        125.796254  0.8306    6.039169         460.180215   \n",
       "\n",
       "   bracket  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(search.history_)\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustrates the history after every `partial_fit` call. There's also an attributed `model_history_` that records the history for each model (it's a reorganization of `history_`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covered basic usage `HyperbandSearchCV`. The following documentation and resources might be useful to learn more about `HyperbandSearchCV`, including some of the finer use cases:\n",
    "\n",
    "* [A talk](https://www.youtube.com/watch?v=x67K9FiPFBQ) introducing `HyperbandSearchCV` to the SciPy 2019 audience and the [corresponding paper](https://conference.scipy.org/proceedings/scipy2019/pdfs/scott_sievert.pdf)\n",
    "* [HyperbandSearchCV's documentation](https://ml.dask.org/modules/generated/dask_ml.model_selection.HyperbandSearchCV.html)\n",
    "\n",
    "Performance comparisons can be found in the SciPy 2019 talk/paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
